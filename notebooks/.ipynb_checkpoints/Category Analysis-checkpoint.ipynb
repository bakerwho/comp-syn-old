{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import colorio\n",
    "import colorsys\n",
    "import matplotlib.colors as colors\n",
    "from PIL import Image\n",
    "\n",
    "import scipy\n",
    "import pylab\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "cmap = cm.plasma(np.linspace(0.0, 1, 3))\n",
    "sch.set_link_color_palette([colors.rgb2hex(rgb[:3]) for rgb in cmap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jzazbz_map = np.load('jzazbz_array.npy', encoding = 'latin1')\n",
    "\n",
    "def rgb_array_to_jzazbz_array(rgb_array):\n",
    "    jzazbz_array = np.zeros(rgb_array.shape)\n",
    "    for i in range(rgb_array.shape[0]):\n",
    "        for j in range(rgb_array.shape[1]):\n",
    "            jzazbz_array[i][j] = jzazbz_map[rgb_array[i][j][0]][rgb_array[i][j][1]][rgb_array[i][j][2]]\n",
    "    return jzazbz_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_dict(words, path_to_words, compress=True, compress_dim=300, complexity_dim=3):\n",
    "    img_dict = {}\n",
    "    img_array_dict = {}\n",
    "    img_array_complexity_dict = {}\n",
    "    for word in words:\n",
    "        img = []\n",
    "        img_array = []\n",
    "        img_array_complexity = []\n",
    "        folder = path_to_words + '{}'.format(word)\n",
    "        pics = [name for name in os.listdir(folder) if os.path.isfile(os.path.join(folder, name))]\n",
    "        for pic in pics:\n",
    "            filename = 'downloads/{}/{}'.format(word,pic)\n",
    "            if os.path.splitext(filename)[1] != '.svg':\n",
    "                try:\n",
    "                    img_raw = Image.open(filename)\n",
    "                    if compress == True:\n",
    "                        img_compress = img_raw.resize((compress_dim,compress_dim),Image.ANTIALIAS)\n",
    "                        if np.shape(np.array(img_compress)) == (compress_dim, compress_dim, 3):\n",
    "                            img.append(img_compress)\n",
    "                            img_array.append(np.array(img_compress))\n",
    "                            img_compress_complexity = img_raw.resize((complexity_dim,complexity_dim),Image.ANTIALIAS)\n",
    "                            img_array_complexity.append(np.array(img_compress_complexity))\n",
    "                except:\n",
    "                    pass\n",
    "        img_dict[word] = img\n",
    "        img_array_dict[word] = img_array\n",
    "        img_array_complexity_dict[word] = img_array_complexity\n",
    "    return img_dict, img_array_dict, img_array_complexity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_distributions(img_dict, jzazbz=True, hsv=True, rgb=True, spacing=36):\n",
    "    jzazbz_dict = {}\n",
    "    jzazbz_dict_dist = {}\n",
    "    hsv_dict = {}\n",
    "    rbg_dict = {}\n",
    "    if jzazbz == True:\n",
    "        for key in img_dict:\n",
    "            jzazbz = []\n",
    "            dist_array = []\n",
    "            for i in range(len(img_dict[key])):\n",
    "                jzazbz_temp = rgb_array_to_jzazbz_array(img_array_dict[key][i])\n",
    "                jzazbz.append(jzazbz_temp)\n",
    "                dist = np.ravel(np.histogramdd(np.reshape(jzazbz_temp[:,:,:],(90000,3)), \n",
    "                                      bins=(np.linspace(0,0.167,3),np.linspace(-0.1,0.11,3),\n",
    "                                           np.linspace(-0.156,0.115,3)), density=True)[0])\n",
    "                dist_array.append(dist)\n",
    "            jzazbz_dict[key] = jzazbz\n",
    "            jzazbz_dict_dist[key] = dist_array#jzazbz\n",
    "            #distribution_dict[key] = dist_array\n",
    "    if hsv == True:\n",
    "        h_dict, s_dict, v_dict = {}, {}, {}\n",
    "        for key in img_dict:\n",
    "            dist_array, h, s, v = [], [], [], []\n",
    "            for i in range(len(img_dict[key])):\n",
    "                hsv_array = colors.rgb_to_hsv(img_array_dict[key][i]/255.)\n",
    "                dist = np.histogram(360.*np.ravel(hsv_array[:,:,0]),\n",
    "                                    bins=np.arange(0,360+spacing,spacing),\n",
    "                                    density=True)[0]\n",
    "                dist_array.append(dist)\n",
    "                h.append(np.mean(np.ravel(hsv_array[:,:,0])))\n",
    "                s.append(np.mean(np.ravel(hsv_array[:,:,1])))\n",
    "                v.append(np.mean(np.ravel(hsv_array[:,:,2])))\n",
    "            hsv_dict[key] = dist_array\n",
    "            #h_dict[key], s_dict[key], v_dict[key] = h, s, v\n",
    "    if rgb == True:\n",
    "        rgb_dict = {}\n",
    "        rgb_dict_dist = {}\n",
    "        for key in img_dict:\n",
    "            rgb = []\n",
    "            dist_array = []\n",
    "            for i in range(len(img_dict[key])):\n",
    "                r = np.sum(np.ravel(img_dict[key][i][:,:,0]))\n",
    "                g = np.sum(np.ravel(img_dict[key][i][:,:,1]))\n",
    "                b = np.sum(np.ravel(img_dict[key][i][:,:,2]))\n",
    "                tot = 1.*r+g+b\n",
    "                rgb.append([r/tot,g/tot,b/tot])\n",
    "                dist = np.ravel(np.histogramdd(np.reshape(img_array_dict[key][i],(90000,3)), \n",
    "                                      bins=(np.linspace(0,255,3),np.linspace(0,255,3),\n",
    "                                           np.linspace(0,255,3)), density=True)[0])\n",
    "                dist_array.append(dist)\n",
    "            rgb_dict[key] = rgb\n",
    "            rgb_dict_dist[key] = dist_array\n",
    "#        return jzazbz_dict, distribution_dict, h_dict, s_dict, v_dict, rgb_dict\n",
    "    return jzazbz_dict, jzazbz_dict_dist, hsv_dict, rgb_dict, rgb_dict_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_img_array(words, img_array_dict, compress_dim=300):\n",
    "    compressed_img_array_dict = {}\n",
    "    for word in words:\n",
    "        compressed_img_array = np.zeros((compress_dim,compress_dim,3))\n",
    "        for n in range(len(img_array_dict[word])):\n",
    "            if np.shape(img_array_dict[word][n]) == (compress_dim, compress_dim, 3):\n",
    "                for i in range(compress_dim):\n",
    "                    for j in range(compress_dim):\n",
    "                        compressed_img_array[i][j] += img_array_dict[word][n][i][j]/(1.*len(img_array_dict[word]))\n",
    "        compressed_img_array_dict[word] = compressed_img_array\n",
    "    return compressed_img_array_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_between_images(rgb_dict, symmetrized=True):\n",
    "    entropy_dict = {}\n",
    "    entropy_dict_js = {}\n",
    "    for key in rgb_dict:\n",
    "        entropy_array = []\n",
    "        entropy_array_js = []\n",
    "        for i in range(len(rgb_dict[key])):\n",
    "            for j in range(len(rgb_dict[key])):\n",
    "                if symmetrized == True:\n",
    "                    mean = (rgb_dict[key][i] + rgb_dict[key][j])/2.\n",
    "                    entropy_array.append((scipy.stats.entropy(rgb_dict[key][i],rgb_dict[key][j])+scipy.stats.entropy(rgb_dict[key][j],rgb_dict[key][i]))/2.)\n",
    "                    entropy_array_js.append((scipy.stats.entropy(rgb_dict[key][i],mean) + scipy.stats.entropy(rgb_dict[key][j],mean))/2.)\n",
    "                else:\n",
    "                    entropy_array.append(scipy.stats.entropy(rgb_dict[key][i],rgb_dict[key][j]))\n",
    "        entropy_dict[key] = entropy_array\n",
    "        entropy_dict_js[key] = entropy_array_js\n",
    "    return entropy_dict, entropy_dict_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_between_labels(rgb_dict, words, symmetrized=True):\n",
    "    mean_rgb_dict = {}\n",
    "    for key in rgb_dict:\n",
    "        mean_rgb_array = np.mean(np.array(rgb_dict[key]),axis=0)\n",
    "        mean_rgb_dict[key] = mean_rgb_array\n",
    "    labels_entropy_dict = {}\n",
    "    labels_entropy_dict_js = {}\n",
    "    color_sym_matrix = []\n",
    "    color_sym_matrix_js = []\n",
    "    for word1 in words:\n",
    "        row = []\n",
    "        row_js = []\n",
    "        for word2 in words:\n",
    "            if symmetrized == True:\n",
    "                mean = (mean_rgb_dict[word1] + mean_rgb_dict[word2])/2.\n",
    "                entropy = (scipy.stats.entropy(mean_rgb_dict[word1],mean_rgb_dict[word2])+scipy.stats.entropy(mean_rgb_dict[word2],mean_rgb_dict[word1]))/2.\n",
    "                entropy_js = (scipy.stats.entropy(mean_rgb_dict[word1],mean) + scipy.stats.entropy(mean_rgb_dict[word2],mean))/2.\n",
    "            else:\n",
    "                entropy = scipy.stats.entropy(mean_rgb_dict[word1],mean_rgb_dict[word2])\n",
    "                entropy_js = []\n",
    "            row.append(entropy)\n",
    "            row_js.append(entropy_js)\n",
    "            labels_entropy_dict[word1 + word2] = entropy\n",
    "            labels_entropy_dict_js[word1 + word2] = entropy_js\n",
    "        color_sym_matrix.append(row)\n",
    "        color_sym_matrix_js.append(row_js)\n",
    "    return labels_entropy_dict, color_sym_matrix, labels_entropy_dict_js, color_sym_matrix_js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jzazbz_dict_discipline = {}\n",
    "rgb_dict_discipline = {}\n",
    "entropy_dict_js_discipline = {}\n",
    "cross_entropy_dict_js_discipline = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('super_disc.pickle', 'rb') as handle:\n",
    "    disciplines_pickle = pickle.load(handle)#, encoding=\"latin1\")\n",
    "    \n",
    "with open('sub_disc.pickle', 'rb') as handle:\n",
    "    subdisciplines_pickle = pickle.load(handle)#, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_words = 'Data/categories/disciplines/'\n",
    "discipline_words = disciplines_pickle.keys()\n",
    "\n",
    "img_dict, img_array_dict, img_array_complexity_dict = get_img_dict(discipline_words, path_to_words)\n",
    "jzazbz_dict, jzazbz_dict_dist, hsv_dict, rgb_dict, rgb_dict_dist = get_color_distributions(img_array_dict, jzazbz=True, spacing=36)\n",
    "entropy_dict, entropy_dict_js = cross_entropy_between_images(jzazbz_dict_dist)\n",
    "cross_entropy_between_labels_dict, cross_entropy_matrix, cross_entropy_between_labels_dict_js, cross_entropy_matrix_js = cross_entropy_between_labels(jzazbz_dict_dist, discipline_words, symmetrized=True)\n",
    "compressed_img_array_dict = compress_img_array(discipline_words, img_array_dict)\n",
    "\n",
    "jzazbz_dict_discipline['discipline'] = jzazbz_dict\n",
    "rgb_dict_discipline['discipline'] = rgb_dict\n",
    "entropy_dict_js_discipline['discipline'] = entropy_dict_js\n",
    "cross_entropy_dict_js_discipline['discipline'] = cross_entropy_matrix_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jzazbz_dict_discipline['subdiscipline'] = {}\n",
    "entropy_dict_js_discipline['subdiscipline'] = {}\n",
    "cross_entropy_dict_js_discipline['subdiscipline'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in discipline_words:\n",
    "    path_to_words = 'Data/categories/subdisciplines/{}/'.format(word)\n",
    "    subdiscipline_words = subdisciplines_pickle[word].keys()\n",
    "    img_dict, img_array_dict, img_array_complexity_dict = get_img_dict(subdiscipline_words, path_to_words)\n",
    "    jzazbz_dict, jzazbz_dict_dist, hsv_dict, rgb_dict, rgb_dict_dist = get_color_distributions(img_array_dict, jzazbz=True, spacing=36)\n",
    "    entropy_dict, entropy_dict_js = cross_entropy_between_images(jzazbz_dict_dist)\n",
    "    cross_entropy_between_labels_dict, cross_entropy_matrix, cross_entropy_between_labels_dict_js, cross_entropy_matrix_js = cross_entropy_between_labels(jzazbz_dict_dist, subdiscipline_words, symmetrized=True)\n",
    "    jzazbz_dict_discipline['subdiscipline'][word] = jzazbz_dict\n",
    "    entropy_dict_js_discipline['subdiscipline'][word] = entropy_dict_js\n",
    "    cross_entropy_dict_js_discipline['subdiscipline'][word] = cross_entropy_matrix_js"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dist_dict = {}\n",
    "for word in discipline_words:\n",
    "    avg_dist = np.mean(jzazbz_dict_dist[word],axis=0)\n",
    "    avg_dist_dict[word] = avg_dist\n",
    "    \n",
    "X = np.zeros((len(discipline_words),8))\n",
    "i = 0\n",
    "for word in discipline_words:\n",
    "    X[i] = avg_dist_dict[word]\n",
    "    i +=1\n",
    "    \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "\n",
    "labels = kmeans.predict(X)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "avg_rgb_dict = {}\n",
    "for word in discipline_words:\n",
    "    avg_rgb = np.mean(np.mean(np.mean(jzazbz_dict[word],axis=0),axis=0),axis=0)#np.mean(disciplinejzazbz_dict[word],axis=0)\n",
    "    avg_rgb_dict[word] = avg_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorsmap = map(lambda x: {1: 'r', 0: 'b', 2: 'g', 3:'m', 4:'k', 5:'brown'}, labels)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "i =0\n",
    "for word in ['mathematics']:#discipline_words:\n",
    "    ax.scatter(avg_rgb_dict[word][0], avg_rgb_dict[word][1], avg_rgb_dict[word][2], \n",
    "               c=colorsmap[0][labels[i]], label=word, marker='o')#colorsmap[0][labels[i]]\n",
    "    i+=1\n",
    "    \n",
    "#encircle(x2, y2, ec=\"orange\", fc=\"none\")\n",
    "\n",
    "ax.legend(loc=1,bbox_to_anchor=(2, 1.05),ncol=2)\n",
    "ax.set_xlabel('r')\n",
    "ax.set_ylabel('g')\n",
    "ax.set_zlabel('b')\n",
    "\n",
    "plt.savefig('discipline_clustering.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.log2(np.exp(np.matrix(cross_entropy_dict_js_discipline['discipline'])))\n",
    "condensedD = squareform(D)\n",
    "\n",
    "# Compute and plot first dendrogram.\n",
    "fig = pylab.figure(figsize=(10,10))\n",
    "ax1 = fig.add_axes([0.162,0.1,0.125,0.6])\n",
    "Y = sch.linkage(condensedD, method='centroid')\n",
    "Z1 = sch.dendrogram(Y, orientation='left', above_threshold_color='dimgrey')\n",
    "\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.axis('off')\n",
    "\n",
    "# Compute and plot second dendrogram.\n",
    "ax2 = fig.add_axes([0.3,0.71,0.6,0.125])\n",
    "Y = sch.linkage(condensedD, method='centroid')\n",
    "Z2 = sch.dendrogram(Y, above_threshold_color='dimgrey')\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.axis('off')\n",
    "\n",
    "# Plot distance matrix.\n",
    "axmatrix = fig.add_axes([0.3,0.1,0.6,0.6])\n",
    "idx1 = Z1['leaves'][::-1]\n",
    "idx2 = Z2['leaves']\n",
    "D = D[idx1,:]\n",
    "D = D[:,idx2]\n",
    "im = axmatrix.matshow(D, aspect='auto', origin='lower', cmap=sns.cubehelix_palette(light=1, as_cmap=True, hue=0.),\n",
    "                     vmin=D.min(),vmax=D.max())\n",
    "axmatrix.set_xticks([])\n",
    "axmatrix.set_yticks([])\n",
    "\n",
    "axmatrix.set_xticks(range(len(discipline_words_plot)))\n",
    "axmatrix.set_xticklabels(np.array(discipline_words_plot)[idx1], minor=False, fontsize=13)\n",
    "axmatrix.xaxis.set_label_position('bottom')\n",
    "axmatrix.xaxis.tick_bottom()\n",
    "\n",
    "pylab.xticks(rotation=-90)\n",
    "\n",
    "axmatrix.set_yticks(range(len(discipline_words_plot)))\n",
    "axmatrix.set_yticklabels(np.array(discipline_words_plot)[idx2], minor=False, fontsize=13)\n",
    "axmatrix.yaxis.set_label_position('right')\n",
    "axmatrix.yaxis.tick_right()\n",
    "\n",
    "#axcolor = fig.add_axes([0.94,0.1,0.02,0.6])\n",
    "# Plot colorbar.\n",
    "axcolor = fig.add_axes([1.05,0.1,0.02,0.6])\n",
    "cbar = pylab.colorbar(im, cax=axcolor)\n",
    "cbar.ax.set_yticks([0,0.005,0.01,0.015,0.02,0.025,0.03])\n",
    "cbar.ax.set_yticklabels(['0','','0.01','','0.02','',0.03],fontsize=10)\n",
    "cbar.set_label('Jensen-Shannon Divergence [bits]', labelpad=24,rotation=270, fontsize=16)\n",
    "fig.show()\n",
    "fig.savefig('dendrogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discipline_branching_factor = np.zeros(len(discipline_words))\n",
    "discipline_precision = np.zeros(len(discipline_words))\n",
    "discipline_entropy = np.zeros(len(discipline_words))\n",
    "\n",
    "i = 0\n",
    "for word in discipline_words:\n",
    "    discipline_branching_factor[i] = disciplines_pickle[word]['branching_fact']\n",
    "    discipline_precision[i] = disciplines_pickle[word]['precision']\n",
    "    discipline_entropy[i] = np.mean(np.array(entropy_dict_js_discipline['discipline'][word]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.scatter(discipline_branching_factor, discipline_entropy)\n",
    "#plt.scatter(genre_branching_factor, genre_entropy)\n",
    "\n",
    "plt.xticks([1,10,100], fontsize=10)\n",
    "plt.yticks([0.2,0.3,0.4], fontsize=10)\n",
    "plt.gca().set_yticklabels([r'0.2',r'0.3',r'0.4'],minor=True, fontsize=10)\n",
    "\n",
    "plt.xlabel(r'WordNet Branching Factor',fontsize=20, labelpad=8)\n",
    "plt.ylabel('Within-Label\\n JS Divergence [bits]',fontsize=20, labelpad=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "#plt.hist(np.ravel(cross_entropy_matrix_js),color='r',normed=True,alpha=0.5, label='physics subdisciplines')\n",
    "#plt.hist(np.ravel(biocross_entropy_matrix_js),color='k',alpha=0.5,normed=True, label='bio subdisciplines')\n",
    "plt.hist(np.ravel(np.log2(np.exp(cross_entropy_matrix_js_rand))),color='k',alpha=0.5,linewidth=2.,histtype='step',normed=True, label='random nouns')\n",
    "plt.hist(np.ravel(np.log2(np.exp(np.matrix(cross_entropy_dict_js_discipline['discipline'])))),color='b',normed=True, label='disciplines', alpha=0.35)\n",
    "plt.hist(np.ravel(np.log2(np.exp(np.matrix(cross_entropy_dict_js_discipline['subdiscipline']['physics'])))),color='g',normed=True, label='subdisciplines', alpha=0.35)\n",
    "#plt.hist(genres,color='g',normed=True, bins=5, label='music genres', alpha=0.3)\n",
    "\n",
    "plt.xlim(-0.025,0.65)\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=1, frameon=False, fontsize=16)\n",
    "#plt.xlim(0.01,0.25)\n",
    "\n",
    "plt.xticks([0,0.15,0.3,0.45,0.6], fontsize=12)\n",
    "plt.yticks([0.1,1.0,10], fontsize=12)\n",
    "\n",
    "plt.xlabel(r'Jensen-Shannon Divergence [bits]', fontsize=18)\n",
    "plt.ylabel(r'$\\mathcal{P}(\\rm{JS\\ Divergence})$', fontsize=18)\n",
    "plt.title('Perceptually Uniform Binning', fontsize=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
